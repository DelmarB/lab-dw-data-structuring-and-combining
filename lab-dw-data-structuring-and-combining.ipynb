{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {
    "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e"
   },
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {
    "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986"
   },
   "source": [
    "## Challenge 1: Combining & Cleaning Data\n",
    "\n",
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the links below.\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Note that you'll need to clean and format the new data.\n",
    "\n",
    "Observation:\n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e10d44-317e-41ca-84b8-0ddb49ec1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soulu\\Desktop\\ironhack\\week2\\day3\\lab-dw-data-structuring-and-combining\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Check the current working directory\n",
    "print(os.path.exists('df2_clean.csv'))  # Returns True if the file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {
    "id": "492d06e3-92c7-4105-ac72-536db98d3244"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1071, 11)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# CLEAN DF FROM FIRST DATASET\n",
    "import pandas as pd\n",
    "url = 'df2_clean.csv'\n",
    "#df2 = cleaned first dataset\n",
    "df2 = pd.read_csv(url)\n",
    "#df2.head()\n",
    "#df2.dtypes\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1192fc4-b610-4dfd-a3f8-7af256aa5e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8495212-21b1-424a-bdcc-74248e474910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer                       0\n",
      "state                          0\n",
      "gender                         0\n",
      "education                      0\n",
      "customer_lifetime_value        0\n",
      "income                         0\n",
      "monthly_premium_auto           0\n",
      "number_of_open_complaints    796\n",
      "total_claim_amount             0\n",
      "policy_type                    0\n",
      "vehicle_class                  0\n",
      "dtype: int64\n",
      "\n",
      "(996, 11)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')  # Ensure current directory is in the path\n",
    "\n",
    "import pandas as pd\n",
    "url_2 = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv'\n",
    "df3 = pd.read_csv(url_2)\n",
    "\n",
    "import importlib\n",
    "import cleaning_tool\n",
    "importlib.reload(cleaning_tool)  # This ensures it reloads any edits\n",
    "\n",
    "df3.columns = df3.columns.str.replace(\" \", \"_\")\n",
    "df3.columns = [col.lower() for col in df3.columns]\n",
    "df3.rename(columns={'st': 'state'}, inplace=True)\n",
    "df3['state'] = df3['state'].replace({'AZ': 'Arizona'})\n",
    "df3['education'] = df3['education'].replace({'Bachelors': 'Bachelor'})\n",
    "df3['customer_lifetime_value'] = df3['customer_lifetime_value'].astype(str).str.replace('%', '')\n",
    "\n",
    "df3['vehicle_class'] = df3['vehicle_class'].apply(lambda x: 'Luxury' if isinstance(x, str) and 'luxury' in x.lower() else x)\n",
    "df3['vehicle_class'].unique()\n",
    "\n",
    "# splits according to slash '/' and takes only the value of index 1 [1] the second one\n",
    "df3['number_of_open_complaints'] = df3['number_of_open_complaints'].apply(lambda x: int(str(x).split('/')[1]) if isinstance(x, str) and '/' in x else pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "\n",
    "#change dtyps of columns\n",
    "cols_to_convert = ['customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints']\n",
    "df3[cols_to_convert] = df3[cols_to_convert].astype('float64')\n",
    "\n",
    "# count rows where the whole row is nan\n",
    "#(df3.isna().all(axis=1)).sum()\n",
    "\n",
    "# amount of NaN in each column\n",
    "#df3.isna().sum()\n",
    "\n",
    "# Median value (most frequent value) because df2 we used median to replace 0\n",
    "median_value_3 = df3['income'].median()\n",
    "\n",
    "# replace 0 values in column income with the median value of the list\n",
    "df3=df3.replace({'income': {0: median_value_3}})\n",
    "\n",
    "# amount of 0 values in each column\n",
    "#print((df3 == 0).sum())\n",
    "\n",
    "print()\n",
    "print(df3.shape) # amount of rows and columns\n",
    "\n",
    "#df3.tail()\n",
    "#df3.dtypes\n",
    "#df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01f97e31-9ac2-4082-927a-b88020814a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer                        0\n",
      "state                           0\n",
      "customer_lifetime_value         0\n",
      "education                       0\n",
      "gender                          0\n",
      "income                          0\n",
      "monthly_premium_auto            0\n",
      "number_of_open_complaints    5629\n",
      "policy_type                     0\n",
      "total_claim_amount              0\n",
      "vehicle_class                   0\n",
      "dtype: int64\n",
      "\n",
      "(7070, 11)\n"
     ]
    }
   ],
   "source": [
    "#THIRD dataset to be merged --> df4\n",
    "\n",
    "import pandas as pd\n",
    "url_2 = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv'\n",
    "df4 = pd.read_csv(url_2)\n",
    "\n",
    "import importlib\n",
    "import cleaning_tool\n",
    "importlib.reload(cleaning_tool)  # This ensures it reloads any edits\n",
    "\n",
    "\n",
    "\n",
    "df4.columns = df4.columns.str.replace(\" \", \"_\")\n",
    "df4.columns = [col.lower() for col in df4.columns]\n",
    "#df4.rename(columns={'st': 'state'}, inplace=True)\n",
    "#df4['state'] = df4['state'].replace({'AZ': 'Arizona'})\n",
    "#df4['education'] = df4['education'].replace({'Bachelors': 'Bachelor'})\n",
    "#df4['customer_lifetime_value'] = df4['customer_lifetime_value'].astype(str).str.replace('%', '')\n",
    "\n",
    "df4['vehicle_class'] = df4['vehicle_class'].apply(lambda x: 'Luxury' if isinstance(x, str) and 'luxury' in x.lower() else x)\n",
    "\n",
    "#df4['vehicle_class'].unique()\n",
    "\n",
    "# splits according to slash '/' and takes only the value of index 1 [1] the second one\n",
    "#df4['number_of_open_complaints'] = df3['number_of_open_complaints'].apply(lambda x: int(str(x).split('/')[1]) if isinstance(x, str) and '/' in x else pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "#change dtyps of columns\n",
    "cols_to_convert_2 = ['income', 'monthly_premium_auto', 'number_of_open_complaints']\n",
    "df4[cols_to_convert_2] = df4[cols_to_convert_2].astype('float64')\n",
    "\n",
    "# count rows where the whole row is nan\n",
    "#(df4.isna().all(axis=1)).sum()\n",
    "\n",
    "# amount of NaN in each column\n",
    "#df4.isna().sum()\n",
    "\n",
    "# Median value (most frequent value) because df2 we used median to replace 0\n",
    "median_value_4 = df4['income'].median()\n",
    "\n",
    "# replace 0 values in column income with the median value of the list\n",
    "df4=df4.replace({'income': {0: median_value_4}})\n",
    "\n",
    "# amount of 0 values in each column\n",
    "print((df4 == 0).sum())\n",
    "\n",
    "print()\n",
    "print(df4.shape) # amount of rows and columns\n",
    "#df4.head()\n",
    "#df4.tail()\n",
    "#df4.dtypes\n",
    "#df4.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8106d6c-bbfe-4659-9712-5a7f57c191c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9137, 11)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proof if all 3 df match\n",
    "#set(df2.columns) == set(df3.columns) == set(df4.columns)\n",
    "\n",
    "combined_df = pd.concat([df2, df3, df4], ignore_index=True)\n",
    "\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {
    "id": "31b8a9e7-7db9-4604-991b-ef6771603e57"
   },
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {
    "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {
    "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10910, 26)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "#FOURTH dataset to be merged --> df5\n",
    "\n",
    "import pandas as pd\n",
    "url_2 = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv'\n",
    "df5 = pd.read_csv(url_2)\n",
    "\n",
    "# Drop the 'Unnamed:_0' column\n",
    "df5 = df5.drop(columns=['unnamed:_0'])\n",
    "\n",
    "#change effective_to_date column to datetime dtype\n",
    "df5['effective_to_date'] = pd.to_datetime(df5['effective_to_date']).dt.normalize()\n",
    "\n",
    "# Check if values are within a small range of 15.14907074\n",
    "tolerance = 1e-5  # tolerance value to account for floating point precision\n",
    "close_values = (df5['months_since_last_claim'] - 15.14907074).abs() < tolerance\n",
    "\n",
    "# Count how many values are close to 15.14907074\n",
    "#count = close_values.sum()\n",
    "#print(f\"The value close to 15.14907074 appears {count} times.\")\n",
    "\n",
    "# Check for unique values in the column\n",
    "#unique_values = df5['months_since_last_claim'].unique()\n",
    "#print(f\"Unique values in 'months_since_last_claim': {unique_values}\")\n",
    "\n",
    "# Check first few rows of the column\n",
    "#print(df5[['months_since_last_claim']].head(30))\n",
    "\n",
    "# round down the multiple showing of 15.14907074 and save column as an int\n",
    "df5['months_since_last_claim'] = df5['months_since_last_claim'].round().astype('int64')\n",
    "\n",
    "#change Medsize to Medium to match other sizes\n",
    "df5['vehicle_size'] = df5['vehicle_size'].replace('Medsize', 'Medium')\n",
    "\n",
    "#print(df5.tail())\n",
    "#df5['month'].unique()\n",
    "#display(df5.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {
    "id": "df35fd0d-513e-4e77-867e-429da10a9cc7"
   },
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "078fdebc-a361-4574-a3e4-bb54468e1ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               monthly_premium_auto  Percentage\n",
      "sales_channel                                  \n",
      "Agent                        386335       38.00\n",
      "Branch                       280953       27.63\n",
      "Call Center                  197970       19.47\n",
      "Web                          151511       14.90\n",
      "Total                       1016769      100.00\n"
     ]
    }
   ],
   "source": [
    "# Create pivot table to calculate total revenue (monthly_premium_auto) for each sales channel\n",
    "pivot_table = df5.pivot_table(\n",
    "    values='monthly_premium_auto', \n",
    "    index='sales_channel', \n",
    "    aggfunc='sum'\n",
    ").round(2)\n",
    "\n",
    "# Add the sum row at the bottom\n",
    "pivot_table.loc['Total'] = pivot_table.sum()\n",
    "\n",
    "# Calculate percentages of the total (excluding 'Total' row)\n",
    "pivot_table_percentage = pivot_table / pivot_table.loc['Total'] * 100\n",
    "\n",
    "# Round the percentages to 2 decimal places\n",
    "pivot_table_percentage = pivot_table_percentage.round(2)\n",
    "\n",
    "# Add the percentages to the pivot table\n",
    "pivot_table['Percentage'] = pivot_table_percentage['monthly_premium_auto']\n",
    "\n",
    "# Display the pivot table with the total and percentage\n",
    "print(pivot_table)\n",
    "\n",
    "\"\"\"\n",
    "Insight:\n",
    "- Top Sales Channels: The Agent channel generated the highest total revenue with 38.00%,\n",
    "  followed by Branch with 27.63%, and Call Center with 19.47%.\n",
    "- Combined, these top three contribute over 85% of total revenue.\n",
    "- The Web channel underperforms at 14.90%, suggesting potential for optimization.\n",
    "- Recommendation: Investigate why Agent and Branch outperform others, and improve Web strategy.\n",
    "\"\"\"\n",
    "\n",
    "#for col in df5.columns:\n",
    "#    print(col)\n",
    "\n",
    "#df5.head()\n",
    "\n",
    "# The sales channel ordered from top to b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {
    "id": "640993b2-a291-436c-a34d-a551144f8196"
   },
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "863de69d-bd39-4784-a927-145fc9f11efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education  Bachelor  College   Doctor  High School or Below   Master\n",
      "gender                                                              \n",
      "F           7874.27  7748.82  7328.51               8675.22  8157.05\n",
      "M           7703.60  8052.46  7415.33               8149.69  8168.83\n"
     ]
    }
   ],
   "source": [
    "pivot_table = df5.pivot_table(\n",
    "    values='customer_lifetime_value',\n",
    "    index='gender',\n",
    "    columns='education',\n",
    "    aggfunc='mean'\n",
    ").round(2)\n",
    "print(pivot_table)\n",
    "\n",
    "\"\"\"\n",
    " Insights:\n",
    "- Master’s degree holders have the highest average customer lifetime value (CLV) for both genders — especially males ($8168.83) and closely followed by females ($8157.05).\n",
    "\n",
    "- Among females, those with High School or Below education actually show the highest CLV ($8675.22), which is an interesting outlier and may warrant deeper analysis.\n",
    "\n",
    "- Doctorate holders have lower CLVs compared to other education levels, especially among females ($7328.51).\n",
    "\n",
    "- CLV values are relatively similar between genders, with slight variations depending on the education level.\n",
    "\n",
    "- Males with College education ($8052.46) have a higher CLV than females with the same level ($7748.82), while in most other categories, females tend to have the edge.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {
    "id": "32c7f2e5-3d90-43e5-be33-9781b6069198"
   },
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {
    "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291"
   },
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {
    "id": "3a069e0b-b400-470e-904d-d17582191be4"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
